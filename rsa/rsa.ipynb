{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representational Similarity Analysis\n",
    "\n",
    "This notebook contains code to reproduce our representational similarity analysis (RSA) for both experimental conditions (sentence condition and picture condition) and the three brain networks (left-hemisphere language netowrk, right-hemisphere language network, and visual network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "from src.paths import ROOT\n",
    "from scipy.stats import spearmanr\n",
    "from src.utils import open_json, dict_to_json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "# from src.best_layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dict with brain RDMs\n",
    "brain_rdms = open_json(ROOT / 'data/participant_rdms.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model rmds for the sentence condition\n",
    "model_rdms = open_json(ROOT / 'data/sentences_model_rdms.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triu_indices = np.triu_indices(n=180, m=180, k=1)\n",
    "\n",
    "# creating a dict to store results\n",
    "rsa_results_sentence = {}\n",
    "\n",
    "for model in model_rdms:\n",
    "    \n",
    "    # creating a sub-dict for each model to store layer-specific correlations\n",
    "    rsa_results_sentence[model] = {}\n",
    "    n_layers = len(model_rdms[model])\n",
    "\n",
    "    for network in ['visual', 'languageLH', 'languageRH']:\n",
    "        rsa_results_sentence[model][network] = {'rho':[], 'pval':[]}\n",
    "        \n",
    "        # selecting the off-diagonal of the brain rdm \n",
    "        brain_rdm = np.array(brain_rdms['sentence'][network])[triu_indices]\n",
    "        \n",
    "        if n_layers > 1:\n",
    "\n",
    "            # iterating through layers\n",
    "            for layer in range(n_layers):\n",
    "\n",
    "                # selecting the off-diagonal of the model rdm \n",
    "                layer_rdm = np.array(model_rdms[model][f\"layer_{layer+1}\"])[triu_indices]\n",
    "\n",
    "                # computing rsa (Spearman correlation)\n",
    "                rho, pval = spearmanr(layer_rdm, brain_rdm)\n",
    "                \n",
    "                # storing result in the dict\n",
    "                rsa_results_sentence[model][network]['rho'].append(rho.item())\n",
    "                rsa_results_sentence[model][network]['pval'].append(pval.item())\n",
    "\n",
    "        else:\n",
    "\n",
    "            for layer in model_rdms[model]:\n",
    "\n",
    "                # selecting the off-diagonal of the model rdm \n",
    "                model_rdm = np.array(model_rdms[model][layer])[triu_indices]\n",
    "\n",
    "                # computing rsa (Spearman correlation)\n",
    "                rho, pval = spearmanr(model_rdm, brain_rdm)\n",
    "\n",
    "                # storing result in the dict\n",
    "                rsa_results_sentence[model][network]['rho'].append(rho.item())\n",
    "                rsa_results_sentence[model][network]['pval'].append(pval.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving result dict as a json\n",
    "dict_to_json(rsa_results_sentence, 'results/rsa_sentence.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing model rmds for the picture condition\n",
    "model_rdms = open_json(ROOT / 'data/picture_model_rdms.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triu_indices = np.triu_indices(n=180, m=180, k=1)\n",
    "\n",
    "# creating a dict to store results\n",
    "rsa_results_picture = {}\n",
    "\n",
    "for model in model_rdms:\n",
    "\n",
    "    # creating a sub-dict for each model to store layer-specific correlations\n",
    "    rsa_results_picture[model] = {}\n",
    "    n_layers = len(model_rdms[model])\n",
    "\n",
    "    for network in ['visual', 'languageLH', 'languageRH']:\n",
    "        rsa_results_picture[model][network] = {'rho':[], 'pval':[]}\n",
    "\n",
    "        # selecting the off-diagonal of the brain rdm \n",
    "        brain_rdm = np.array(brain_rdms['picture'][network])[triu_indices]\n",
    "        \n",
    "        if n_layers > 1:\n",
    "            # iterating through model layers\n",
    "            for layer in range(n_layers):\n",
    "\n",
    "                # selecting the off-diagonal of the model rdm \n",
    "                layer_rdm = np.array(model_rdms[model][f\"layer_{layer+1}\"])[triu_indices]\n",
    "\n",
    "                # computing rsa (Spearman correlation)\n",
    "                rho, pval = spearmanr(layer_rdm, brain_rdm)\n",
    "                \n",
    "                # storing result in the dict\n",
    "                rsa_results_picture[model][network]['rho'].append(rho.item())\n",
    "                rsa_results_picture[model][network]['pval'].append(pval.item())\n",
    "\n",
    "        else:\n",
    "\n",
    "            for layer in model_rdms[model]:\n",
    "\n",
    "                # selecting the off-diagonal of the model rdm \n",
    "                model_rdm = np.array(model_rdms[model][layer])[triu_indices]\n",
    "\n",
    "                # computing rsa (Spearman correlation)\n",
    "                rho, pval = spearmanr(model_rdm, brain_rdm)\n",
    "\n",
    "                # storing result in the dict\n",
    "                rsa_results_picture[model][network]['rho'].append(rho.item())\n",
    "                rsa_results_picture[model][network]['pval'].append(pval.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving result dict as a json\n",
    "dict_to_json(rsa_results_picture, 'results/rsa_picture.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good idea to print the best layers for each network and experimental condition and save them in `src/best_layers.py`, so that they can be easily imported within other modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving best layers\n",
    "best_layers_sentence = {}\n",
    "\n",
    "networks = ['languageLH', 'languageRH', 'visual']\n",
    "\n",
    "for model in ['clip', 'align', 'lxmert', 'visualbert', 'llava', 'llama', 'idefics2', 'mistral', 'bert']:\n",
    "    best_layers_sentence[model]  = {}\n",
    "    for network in networks:\n",
    "        best_layers_sentence[model][network] = f\"layer_{np.array(rsa_results_sentence[model][network]['rho']).argmax()+1}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving best layers\n",
    "best_layers_picture = {}\n",
    "\n",
    "for model in ['lxmert', 'visualbert', 'llava', 'llama', 'idefics2', 'mistral', 'bert']:\n",
    "    best_layers_picture[model]  = {}\n",
    "    for network in networks:\n",
    "        best_layers_picture[model][network] = f\"layer_{np.array(rsa_results_picture[model][network]['rho']).argmax()+1}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests\n",
    "\n",
    "This section of the notebook contains code to reproduce the statistical tests used to assess:\n",
    "\n",
    "1. whether differences in models' brain alignment are statistically significant or not\n",
    "2. whether the most aligned model layer is signicantly more brain-aligned than the other model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reimporting RSA results (if necessary)\n",
    "\n",
    "rsa_results_picture = open_json('results/rsa_picture.json')\n",
    "rsa_results_sentence = open_json('results/rsa_sentence.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests for the differences between models\n",
    "\n",
    "Here, we want to test whether the brain-alignment yielded by each model's best layer is statististically significantly different from the brain alignment produced by other models' best layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dict containing only the best-layer RSA value for each model (sentence condition)\n",
    "\n",
    "sentence_values = {}\n",
    "\n",
    "models = ['clip', 'align', 'lxmert', 'visualbert', 'idefics2', 'llava', 'mistral', 'llama', 'bert', 'glove']\n",
    "networks = ['languageLH', 'languageRH', 'visual']\n",
    "\n",
    "for network in networks:\n",
    "    sentence_values[network] = {}\n",
    "    for i, (model) in enumerate(models):\n",
    "        model_values = np.array(rsa_results_sentence[model][network]['rho'])\n",
    "        sentence_values[network][model] = model_values.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dict containing only the best-layer RSA value for each model (picture condition)\n",
    "\n",
    "picture_values = {}\n",
    "models = ['clip', 'align', 'lxmert', 'visualbert', 'idefics2', 'llava', 'mistral', 'llama', 'bert', 'glove']\n",
    "networks = ['languageLH', 'languageRH', 'visual']\n",
    "\n",
    "for network in networks:\n",
    "    picture_values[network] = {}\n",
    "    for i, (model) in enumerate(models):\n",
    "        model_values = np.array(rsa_results_picture[model][network]['rho'])\n",
    "        picture_values[network][model] = model_values.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing thif function for computing statistical significance\n",
    "from src.statistical_tests import corr_significance_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = ['languageLH', 'languageRH', 'visual']\n",
    "models = ['clip', 'align', 'lxmert', 'visualbert', 'idefics2', 'llava', 'mistral', 'llama', 'bert', 'glove']\n",
    "n = 180\n",
    "size = (n*n-n)/2\n",
    "indices = np.triu_indices(n=len(models), m=len(models), k=1)\n",
    "\n",
    "for ind1, ind2 in zip(indices[0], indices[1]):\n",
    "    \n",
    "    pair_values_sent = []\n",
    "    pair_values_pic = []\n",
    "\n",
    "    # iterating through brain networks\n",
    "    for network in networks:\n",
    "        \n",
    "        # calculating pvalues for the sentence condition\n",
    "        corr1 = sentence_values[network][models[ind1]]\n",
    "        corr2 = sentence_values[network][models[ind2]]\n",
    "        sent_p_val = corr_significance_test(size, corr1=corr1, corr2=corr2)\n",
    "        pair_values_sent.append(round(sent_p_val, 3))\n",
    "        \n",
    "        # calculating pvalues for the picture condition\n",
    "        corr1 = picture_values[network][models[ind1]]\n",
    "        corr2 = picture_values[network][models[ind2]]\n",
    "        pic_p_val = corr_significance_test(size, corr1=corr1, corr2=corr2)\n",
    "        pair_values_pic.append(round(pic_p_val, 3))\n",
    "        \n",
    "    # printing p-values in a latex-friendly format\n",
    "    print(f\"{[models[ind1]]} - {[models[ind2]]} & {pair_values_sent[0]} & {pair_values_pic[0]} & {pair_values_sent[1]} & {pair_values_pic[1]} & {pair_values_sent[2]} & {pair_values_pic[2]}  \\\\\\\\\")\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests for best layer's significance\n",
    "\n",
    "Here, we check whether models' best layer (i.e., the most brain-aligned) is statistically signifcantly more aligned than the other layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_layer_significance(results_dict, model, brain_network):\n",
    "    \n",
    "    '''\n",
    "        This function takes as input a dict storing rsa results (e.g., rsa_results_sentence),\n",
    "        the string indicating a model (which should be a key in results_dict) and the string\n",
    "        indicating a brain network (i.e., 'languageLH', 'languageRH', 'visual'). The function\n",
    "        computes Bonferroni-corrected p-values for the differences between each layer and the \n",
    "        best layer and prints 'True' or 'False' depending on whether the difference is \n",
    "        statistically significant or not.\n",
    "\n",
    "    '''    \n",
    "    \n",
    "    \n",
    "    rsa_vals = np.array(results_dict[model][brain_network]['rho']) # selecting rsa values for the model of interest\n",
    "    \n",
    "    # obtaining index of the best layer and its rsa value\n",
    "    argmax = rsa_vals.argmax().item()\n",
    "    val_max = rsa_vals.max().item()\n",
    "    \n",
    "    n_compar = rsa_vals.shape[0]-1 # defining the number of comparisons as the number of layers - 1 (we don't compare the best layer with itself)\n",
    "\n",
    "    # iterating through layers\n",
    "    for layer in range(rsa_vals.shape[0]):\n",
    "\n",
    "        # skipping the best layer\n",
    "        if layer != argmax:\n",
    "\n",
    "            # computing p-value\n",
    "            pval = corr_significance_test(16110, corr1=val_max, corr2=rsa_vals[layer])\n",
    "\n",
    "            # printing significance of Bonferroni-corrected p-value\n",
    "            print(layer+1, pval<0.05/n_compar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of function use\n",
    "get_best_layer_significance(rsa_results_sentence, 'clip', 'languageLH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picture condition ablation study\n",
    "\n",
    "Here, we recompute RSA for the picture condition in the ablation study where we passed the same input (i.e., only the concept word) to both VLMs and language-only models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant RDMs\n",
    "vlm_rdms = open_json(ROOT / \"data/concept_only_vlm_rdms.json\")\n",
    "lm_rdms = open_json(ROOT / \"data/picture_model_rdms.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlms = ['clip', 'align', 'lxmert', 'visualbert', 'idefics2', 'llava']\n",
    "lms = ['bert', 'mistral', 'llama', 'glove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dict to store vlm results\n",
    "rsa_dict = {}\n",
    "triu_indices = np.triu_indices(n=180, m=180, k=1)\n",
    "\n",
    "\n",
    "for model in vlms:\n",
    "\n",
    "    # creating a dict for every model\n",
    "    rsa_dict[model] = {}\n",
    "\n",
    "    # iterating through networks\n",
    "    for network in brain_rdms['picture']:\n",
    "\n",
    "        # creating RDM\n",
    "        brain_rdm = np.array(brain_rdms['picture'][network])[triu_indices]\n",
    "        rsa_dict[model][network] = {'rho': [], 'pval': []}\n",
    "        \n",
    "        # iterating through layers\n",
    "        for layer in vlm_rdms[model]:\n",
    "            model_rdm = np.array(vlm_rdms[model][layer])[triu_indices]\n",
    "\n",
    "            # computing RSA\n",
    "            rho, pval = spearmanr(model_rdm, brain_rdm) \n",
    "\n",
    "            # storing results in dict\n",
    "            rsa_dict[model][network]['rho'].append(rho.item())\n",
    "            rsa_dict[model][network]['pval'].append(pval.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding to the same dict the best-layer RSA values for the language-only models (we already have these \n",
    "# values stored, so no need to recompute them)\n",
    "\n",
    "for model in lms:\n",
    "\n",
    "    rsa_dict[model] = {}\n",
    "\n",
    "    # iterating through networks\n",
    "    for network in brain_rdms['picture']:\n",
    "\n",
    "        brain_rdm = np.array(brain_rdms['picture'][network])[triu_indices]\n",
    "        rsa_dict[model][network] = {'rho': [], 'pval': []}\n",
    "\n",
    "        # iterating through layers\n",
    "        for layer in lm_rdms[model]:\n",
    "            model_rdm = np.array(lm_rdms[model][layer])[triu_indices]\n",
    "            rho, pval = spearmanr(model_rdm, brain_rdm) \n",
    "            rsa_dict[model][network]['rho'].append(rho.item())\n",
    "            rsa_dict[model][network]['pval'].append(pval.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical tests\n",
    "\n",
    "As for the main experiment, here we have to test whether differences between models' RSA values are statistically significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = ['languageLH', 'languageRH', 'visual']\n",
    "models = ['clip', 'align', 'lxmert', 'visualbert', 'idefics2', 'llava', 'mistral', 'llama', 'bert', 'glove']\n",
    "\n",
    "n = 180\n",
    "size = (n*n-n)/2\n",
    "indices = np.triu_indices(n=len(models), m=len(models), k=1)\n",
    "\n",
    "for network in networks:\n",
    "    print('\\n', network)\n",
    "    \n",
    "    for ind1, ind2 in zip(indices[0], indices[1]):\n",
    "\n",
    "        corr1 = np.array(rsa_dict[models[ind1]][network]['rho']).max()\n",
    "        corr2 = np.array(rsa_dict[models[ind2]][network]['rho']).max()\n",
    "        p_val = corr_significance_test(size, corr1=corr1, corr2=corr2)\n",
    "\n",
    "        # Bonferroni correction\n",
    "        corrected_pval = 0.05 / len(indices[0])\n",
    "        print(models[ind1], models[ind2], round(corrected_pval, 3))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm-brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
